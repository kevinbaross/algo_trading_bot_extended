{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4633d62-a4cf-41f6-b210-03358da668ec",
   "metadata": {},
   "source": [
    "# Main Module\n",
    "    # Call all the functions from other modules here to run the final output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89a053-05c1-424f-a5d8-0a64a8018c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Def SMAs_Function(combined_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadcd65-7b8c-44e3-8f2b-e8bf62d773df",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Imports\n",
    "    from pathlib import Path\n",
    "    import hvplot.pandas\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn import svm\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from pandas.tseries.offsets import DateOffset\n",
    "    from sklearn.metrics import classification_report\n",
    "    # this helps import the dataframe from API Data Calls.ipynb, you need to run the API notebook to get this dataframe\n",
    "    %store -r combined_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb6b4e-587b-4da7-8379-09a1dd1505e2",
   "metadata": {},
   "source": [
    "# All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cc1ff-f551-4775-909a-b10596d17fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bf83c-e4c7-4583-bc4f-ac1dfdf43383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Nasdaq Data Link (Quandl). Use \"pip install nasdaq-data-link\" to install library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from functools import reduce\n",
    "import yfinance as yf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d06da6-bd6d-4d30-9013-0d31b3415305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import StandardScaler and DateOffset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# Import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import a new classifier from SKLearn\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# this helps import the dataframe from API Data Calls.ipynb, you need to run the API notebook to get this dataframe\n",
    "%store -r combined_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45752a-9b9b-4ea4-9a8c-6446aaa5ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Functions\n",
    "#from ipynb.fs.full.Module1_API_Data_Calls.ipynb import data_import_cleanup_function\n",
    "\n",
    "#from ipynb.fs.full.Module2_SMA.ipynb import SMAs_Function\n",
    "\n",
    "#from ipynb.fs.full.Module3_Classifier_Module import classifier_function\n",
    "\n",
    "import Functions_1_2_3_Combined.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63577c0b-c926-4230-a10a-da627087d8ce",
   "metadata": {},
   "source": [
    "# Call Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912b740-926d-4b4c-8880-9e86f7055fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions\n",
    "combined_values = data_import_cleanup_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d4e5b-5a09-49ec-b948-148135ac2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 2_SMAs.ipynb \n",
    "X_train_scaled, y_train, y_test = SMAs_Function(combined_values, short_window = 20, long_window = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76945220-ef95-4f4d-910a-33a3a39b6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 3_Classifier_Module.ipynb \n",
    "model_testing_report, cumulative_return_plot = classifier_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec8cf2-d797-4670-8325-aeb553ec85c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f41c4c2-d2b5-4c55-aa9b-c10ddad97f2e",
   "metadata": {},
   "source": [
    "    ### Step 1: Import the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f90c00-1ce6-40be-af87-239d2eb1b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Filter the date index and close columns\n",
    "    signals_df = combined_values.loc[:, [\"Close\"] [\"value\"]]\n",
    "\n",
    "    # Use the pct_change function to generate  returns from close prices\n",
    "    signals_df[\"Actual Returns\"] = signals_df[\"Close\"].pct_change()\n",
    "\n",
    "    # Drop all NaN values from the DataFrame\n",
    "    signals_df = signals_df.dropna()\n",
    "\n",
    "    # Review the DataFrame\n",
    "    # display(signals_df.head())\n",
    "    # display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf9a5b-7146-458a-8c0c-fc940a3da4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Step 2: Generate trading signals using short- and long-window SMA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6108ad8-396b-401e-9990-6404bd39582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set the short window and long window\n",
    "    short_window = 20\n",
    "    long_window = 100\n",
    "\n",
    "    # Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "    signals_df['SMA_Fast'] = signals_df['Close'].rolling(window=short_window).mean()\n",
    "    signals_df['SMA_Slow'] = signals_df['Close'].rolling(window=long_window).mean()\n",
    "\n",
    "    signals_df = signals_df.dropna()\n",
    "\n",
    "    # Review the DataFrame\n",
    "    display(signals_df.head())\n",
    "    display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd4551-3653-4cc4-8d44-0e33cab43acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize the new Signal column\n",
    "    signals_df['Signal'] = 0.0\n",
    "\n",
    "    # When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "    signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "    # When Actual Returns are less than 0, generate signal to sell stock short\n",
    "    signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "    # Review the DataFrame\n",
    "    display(signals_df.head())\n",
    "    display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11e07d-73d4-48ca-931b-73968e35fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "    signals_df['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a23a14-9e9c-4c1a-a654-87514adb994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "    signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "\n",
    "    # Review the DataFrame\n",
    "    display(signals_df.head())\n",
    "    display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd6d25-e827-4fa3-870e-766a1cfa4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Plot Strategy Returns to examine performance\n",
    "    (1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b103e-296f-4996-94bc-48d6006d98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### Step 3: Split the data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008e3cc-8c91-4549-89fa-f30305855902",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "    X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "\n",
    "    # Review the DataFrame\n",
    "    X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae26751-c204-4189-9727-25232dcd93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create the target set selecting the Signal column and assiging it to y\n",
    "    y = signals_df['Signal']\n",
    "\n",
    "    # Review the value counts\n",
    "    y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfef20-7808-41bc-ae78-d009d176e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select the start of the training period\n",
    "    training_begin = X.index.min()\n",
    "\n",
    "    # Display the training begin date\n",
    "    print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e4ea3-161f-4f7c-a581-ba622cd1b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select the ending period for the training data with an offset of 3 months\n",
    "    training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "    # Display the training end date\n",
    "    print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81acbe-7ad2-4414-ad1c-137bfed7d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate the X_train and y_train DataFrames\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    # Review the X_train DataFrame\n",
    "    X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3de22e-6293-450d-8a2a-1002601bd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate the X_test and y_test DataFrames\n",
    "    X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "    y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "    # Review the X_test DataFrame\n",
    "    X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cbd2b-ba2d-4f7a-acb4-95866dda3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Scale the features DataFrames\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Apply the scaler model to fit the X-train data\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Transform the X_train and X_test DataFrames using the X_scaler\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf69c5-ac37-475e-83e9-c44f22aaea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return  X_train_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2e8a7-620f-4974-9ff5-649217155ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
